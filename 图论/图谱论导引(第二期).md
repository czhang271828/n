# 图谱论导引(第二期)

### $\beta$量之引入

本章主讲图的运算与构造. 承接上一章节的习题解答部分, 我们从谱分解定理
$$
A=\sum_{i=1}^rQ^T\Lambda Q=\sum_{i=1}^r\mu_i P_i
$$
引出图之角矩阵(angle matrix), 其中$\alpha_{ij}=P_ie_j$, $Q=(e_1,\ldots,e_n)$. 鉴于式子
$$
N_k=\sum_{i=1}^r\mu_i^k\|P_i\mathbf 1\|^2
$$
包含$\|P_i\mathbf 1\|$一类值得研究的量, 我们记$\beta_i=\|P_i\mathbf 1\|/\sqrt n$, 从而有归一化式子
$$
\sum_{i=1}^r\beta_i^2=\dfrac{\mathbf 1^T(\sum_{i=1}^r P_i)\mathbf 1}{n}=\dfrac{\mathbf 1^T\mathbf 1}{n}=1.
$$
兹暂对$\beta$量搁置不议, 将以有为. 且看本章笔记正文.

### 图的运算

常见之运算包括取补(complement), 无交并(disjoint union), 连接(join)等. 

取补即使将图中所有点对间的连边关系反转, 即转换一切$i\sim j$至$i\not\sim j$, 同时将一切$i\not\sim j$转化至$i\sim j$. 我们记$G$之补图为$\overline G$, 易知$A(G)+A(\overline G)+I_{|V(G)|}$为全$1$矩阵. 

一簇图$\{G_k\}$的无交并即是字面意思, 即视不交的一簇图为整体, 记作$G_1\dot\cup G_2\dot\cup\cdots\dot\cup G_n=\dot\cup_{i=1}^n G_i$. 举例而言, 完全二部图$K_{m,n}$之补图为$K_m$与$K_n$的无交并. 

两图($G_1$与$G_2$)的连接定义为在$G_1\dot\cup G_2$中连接一切$(v_1,v_2)\in V(G_1)\times V(G_2)$形成的图, 记作$G_1\bigtriangledown G_2$. 例如$K_3\bigtriangledown K_3=K_6$.

值得一提的是, $\overline{G_1\bigtriangledown G_2}=\overline{G_1}\dot\cup\overline{G_2}$. 同样地, $\overline{G_1 \dot\cup G_2}=\overline{G_1}\bigtriangledown\overline{G_2}$. 若记所有简单图之集合为$\mathcal G$, 容易验证$(\mathcal G,\dot\cup)$与$(\mathcal G,\bigtriangledown)$均为半群, 易验证结合律.

### 插曲: Ramsey数

Ramsey数是图论的重要函数之一, 它是一个以两个正整数作为变量的函数. 在组合数学上, Ramsey定理是要解决以下的问题: 要找这样一个最小的数$n$, 使得$n$个人中必定有$k$个人相识或$l$个人互不相识. 这个数记作$R(k,l)$.

已知的Ramsey数甚少, Paul Erdős曾以一个故事来描述寻找拉姆齐数的难度: "想像有队外星人军队在地球降落, 要求取得$R(5,5)$的值, 否则便会毁灭地球. 在此情况下, 我们应该集结所有算力与数学家去尝试寻找这一数值. 若它们要求的是$R(6,6)$的值, 我们要尝试毁灭这班外星人了."

对于$R(3,3)$这般简单情形, 还是可以用枚举之外的方式得出. 倘若以奥数观点视之, 下文诚然舍近求远, 但并非乏善可陈. 自然的建模是将人视作点, 相识则以连边表示, 反之不连边. 此模型下, "两两认识的三个人"对应图$G$中的三角型($K_3$), "两两陌生的三个人"对应补图$\overline G$中的三角形. 求$n=R(3,3)$即是找到正整数$n$, 使得所有$n$顶点的图与其补图的无交并一定包含一个$K_3$.

应先说明$R(3,3)\neq 5$, 考察$C_5$即可($\overline{ C_5}=C+5$). 对任意六个顶点的图$G$, $G$中起始点与终点相同的长为$3$的walks总数为$\mathrm{trace}(A(G)^3)$, 从而$G$中三角形数量为$\dfrac{\mathrm{trace}(A(G)^3)}{6}$. 同理, $\overline G$中三角形之数量为$\dfrac{\mathrm{trace}([J-I-A(G)]^3)}{6}$, 其中$J:=\mathbf 1_{|V|\times |V|}$. 下仅需证明$\mathrm{trace}(A^3)+\mathrm{trace}((J-I-A)^3)>0$即可.

注意到
$$
\begin{align*} 
\mathrm{trace}(A^3)+\mathrm{trace}((J-I-A)^3)=&\mathrm{trace}((J-I)^3-3(J-I)A(J-I-A))\\ 
=&n(n-1)(n-2)-3\mathrm{trace}(JA(J-I-A))\\&+3\mathrm{trace}(A(J-I-A))\\ 
=&n(n-1)(n-2)-3\sum_i( 1^{(j)})(n-1-\mathbf 1^{(j)}) 
\end{align*}.
$$
这里$1^{(j)}$表示第$j$行/列数字$1$的数量。对每个二次式取极值得：
$$
\mathrm{trace}(A^3)+\mathrm{trace}((J-I-A)^3)\geq\left\{\begin{align*}&2k(k-1)(k-2),&& n=2k,\\&(2k+1)k(k-2),&&n=2k+1.\end{align*}\right..
$$
当$k\geq6$时, $\mathrm{trace}(A^3)+\mathrm{trace}((J-I-A)^3)>0$. 因此$R(3,3)=6$. 

### 特征多项式

与线性代数无异, 图$G$的邻接矩阵特征多项式为$\det(xI-A(G))$. 在无歧义的情形下也可直接称之特征多项式, 记作$P_G(x):=\det(xI-A(G))$.

对无交并运算, $A(G_1\dot\cup G_2)=\begin{pmatrix}A(G_1)&O\\O&A(G_2)\end{pmatrix}$, 从而$P_{G_1\dot\cup G_2}(x)=P_{G_1}(x)P_{G_2}(x)$.

对取补图运算(不妨设$|V(G)|=n$), 有
$$
\begin{align*}
P_{\overline G}(x)=&\det(xI-J+I+A)\\
=&\det((x+1)I+A)-\mathbf 1^T\mathrm{adj}((x+1)I+A)\mathbf 1\\
=&(-1)^nP_G(-x-1)(1-\mathbf 1^T((x+1)I+A)^{-1}\mathbf 1)\\
=&(-1)^nP_G(-x-1)\left(1-n\sum_{i=1}^r\dfrac{\beta_i^2}{x+1+\lambda_i}\right)
\end{align*}
$$
同理, 对$\{G_i\}$, 记$n_i=|V(G_i)|$, 则
$$
P_{\overline{\dot\cup_{i=1}^m G_i}}(x)=(-1)^{\sum_{i=1}^n n_i}P_{\dot\cup_{i=1}^m G_i}(-x-1)\left(1-\sum_{i=1}^m\sum_{j=1}^{r_i}\dfrac{n_i(\beta_j^{(i)})^2}{x+1+\lambda_j}\right)
$$
此处特征值之选取取决于谱分解
$$
\begin{pmatrix}A&O\\O&B\end{pmatrix}=\sum_{i=1}^s\lambda_i \begin{pmatrix}P_i^{(1)}&O\\O&P_i^{(1)}\end{pmatrix}.
$$
对$G_1\dot\cup G_2$的$\beta^{(0)}_i$而言, $(n_1+n_2)(\beta_i^{(0)})^2=n_1(\beta_i^{(1)})^2+n_2(\beta_i^{(2)})^2$. 从而
$$
\begin{align*}
P_{\overline {G_1\dot\cup G_2}}(x)=&(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)\left(1-n_1\sum_{i=1}^s\dfrac{(\beta_i^{(1)})^2}{x+1+\lambda_i}-n_2\sum_{i=1}^s\dfrac{(\beta_i^{(1)})^2}{x+1+\lambda_i}\right)\\
=&-(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)\\
&+(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)\left(1-n_1\sum_{i=1}^s\dfrac{(\beta_i^{(1)})^2}{x+1+\lambda_i}\right)\\
&+(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)\left(1-n_2\sum_{i=1}^s\dfrac{(\beta_i^{(2)})^2}{x+1+\lambda_i}\right)\\
=&(-1)^{n_2}P_{\overline {G_1}}(x)P_{G_2}(-x-1)+(-1)^{n_1}P_{\overline {G_2}}(x)P_{G_1}(-x-1)\\
&-(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)
\end{align*}.
$$
因此
$$
\begin{align*}
&P_{G_1\bigtriangledown G_2}(x)+(-1)^{n_1+n_2}P_{G_1\dot\cup G_2}(-x-1)\\=&(-1)^{n_2}P_{\overline {G_1}}(x)P_{G_2}(-x-1)+(-1)^{n_1}P_{\overline {G_2}}(x)P_{G_1}(-x-1)
\end{align*}.
$$
从而有推论
$$
P_{G_1\bigtriangledown G_2}(x)=P_{G_1}(x)P_{G_2}(x)\left(1-n_1n_2\sum_{i=1}^{r_1}\sum_{j=1}^{r_2}\dfrac{(\beta_i^{(1)}\beta_j^{(2)})^2}{(x-\lambda_i^{(1)})(x-\lambda_j^{(2)})}\right).
$$

### 正则图的特征多项式

设$G$, $G_1$, $G_2$分别为以$(n,k)$, $(n_1,k_1)$, $(n_2,k_2)$为系数的正则图. 

首先应注意到$G$与$\overline G$有相同之特征向量.$G$的主特征值$k$对应$\overline G$的主特征值$n-1-k$. $G$的非主特征向量$x$满足$Ax=\lambda x$与$x^T\mathbf 1_n=0$, 从而
$$
(J-I-A)x=Jx-(1+k)x=-(1+k)x.
$$
不难依特征值写出
$$
P_{\overline G}(x)=(-1)^nP_G(-x-1)\dfrac{x-n+k+1}{x+k+1}.
$$
进而有
$$
\begin{align*}
&P_{G_1\bigtriangledown G_2}(x)\\
=&(-1)^{n_2}P_{\overline {G_1}}(x)P_{G_2}(-x-1)+(-1)^{n_1}P_{\overline {G_2}}(x)P_{G_1}(-x-1)-(-1)^{n_1+n_2}P_{G_1}(-x-1)\\
=&\dfrac{P_{G_1}(x)P_{G_2}(x)}{(x-k_1)(x-k_2)}[(x-k_1)(x-k_2)-n_1n_2]\\
=&P_{G_1}(x)P_{G_2}(x)\left(1-\dfrac{n_1n_2}{(x-k_1)(x-k_2)}\right)
\end{align*}.
$$
从而可导出结论
$$
\sum_{i=1}^{r_1}\sum_{j=1}^{r_2}\dfrac{(\beta_i^{(1)}\beta_j^{(2)})^2}{(x-\lambda_i^{(1)})(x-\lambda_j^{(2)})}=\dfrac{1}{(x-k_1)(x-k_2)}.
$$
例如, 棱锥$K_1\dot\cup C_n$的特征多项式为
$$
\begin{align*}
xP_{C_n}(x)\left(1-\dfrac{n}{x(x-2)}\right)&=(x^2-2x-n)\prod_{s=1}^{n-1}(x-2\cos(2\pi s/n))\\
&=\dfrac{x^n-2^n}{x-2}(x^2-2x-n)\\
\end{align*}.
$$
倘若$n_1-k_1=n_2-k_2$, 则$G_1\bigtriangledown G_2$仍为正则图. 对一切满足$n_i-k_i\equiv C$的图序列$\{G_i\}$而言, 记$ k=\sum_i k_i$, $n=\sum_i n_i$, 归纳可得
$$
P_G(x)=(x-k)(x+n-k)^{k-1}\prod_i\dfrac{P_{G_i}(x)}{x-k_i}.
$$

### 路生成函数

类似数理统计中母函数之定义, 路生成函数(walk generating function)定义为
$$
H_G(t)=\sum_{t=1}^\infty N_k t^k=n\sum_{i=1}^r\dfrac{\beta_i^2}{1-t\lambda_i}.
$$
比较前文中$P_{\overline G}(x)$之表达式
$$
P_{\overline G}(x)=(-1)^nP_G(-1-x)\left(1-\dfrac{H_G\left(-\dfrac{1}{x+1}\right)}{1+x}\right).
$$
从而
$$
H_G(1/t)=t\left((-1)^n\dfrac{P_{\overline G}(-1-t)}{P_G(t)}-1\right).
$$
此外, 有下列结论

1. $\displaystyle{H_{\overline G}(t)=\dfrac{H_G(-t/(1+t))}{1+t-tH_G(-t/(1+t))}}$.
2. $H_{G_1\dot\cup G_2}(t)=H_{G_1}(t)+H_{G_2}(t)$.
3. $H_{G_1\bigtriangledown G_2}=\dfrac{H_{G_1}(t)+H_{G_2}(t)+2tH_{G_1}(t)H_{G_2}(t)}{1-t^2 H_{G_1}(t)H_{G_2}(t)}$.

### 图之聚合

试回忆前文归纳证明$P_n$谱之方法. 试问, 若在$G$的某一点$j$上增添一条边(另一端点不在$V(G)$中), 新图$G_j$之特征多项式如何变化?

设$A=A(G)$, $u=(0,1,0,\ldots,0)$. 考虑$\begin{pmatrix}0& u^T\\u&A\end{pmatrix}$之特征多项式, 有
$$
P_{G_j}(x)=xP_G(x)-P_{G-j}(x).
$$
特殊地, 在$P_{n+1}$的一端添上一条边, 则$P_{P_{n+2}}(x)=xP_{P_{n+1}}(x)-P_{P_n}(x)$. 

定义树(tree)为无圈的连通的简单图. 易知树的特征多项式总能通过迭代$P_1$与$P_2$之特征多项式计算. 

下引入图的指标(index, pl. indices), 即最大特征值$\lambda_1$. 据Rayleigh商定义, $\lambda_1=\max\dfrac{v^T Av}{v^Tv}=\max_{\|v\|=1}v^T Av$. 由于$G$由$G_j$删去一点得到, 故可不妨设$A(G)=A$, $A(G_j)=\begin{pmatrix}A&u\\u^T&0\end{pmatrix}$. 对任$\mathbb R^{|V(G_j)|}=\mathbb R^{|V(G)|}\times \mathbb R$中单位向量$y=(x,c)$总有
$$
\lambda_1(G_j)\geq y^TA(G_j)y\geq x^TAx.
$$
取$x$为$\lambda_1(G)$对应的特征向量, 则$\lambda(G)<\lambda(G_j)$. 

记$G_j^n$为在$G$上$j$处添加$P_n$所得的图, $\lambda_1^{(n)}$为相应的最大特征值. 从而得单调递增的序列$\{\lambda_1^{(n)}\}_{n\geq 0}$. 注意到$\lambda_1=\max_{\|v\|=1}v^T Av\leq\|v\|^2\|A\|_\infty=\Delta (G)$, 这里$\Delta (G)$为$\max_{v\in V(G)}\deg(v)$. 而$\Delta(G_j^n)=\Delta (G)+1$, 故序列$\{\lambda_1^{(n)}\}$存在上确界. 下将求得该上确界. 

类比$\Delta (G)$之定义, 可作$\delta (G):=\min_{v\in V(G)}\deg(v)$. 同理有结论$\delta(G)\leq\lambda_1\leq\Delta(G)$. 从而$\{\lambda_1^{(n)}\}$在某一项后不小于$2$. 记
$$
\begin{align*}
f_0(x)&=P_G(x)\\
f_1(x)&=xP_G(x)-P_{G-j}(x)\\
f_{n+2}(x)&=xf_{n+1}(x)-f_n(x),\quad n\in\mathbb N.
\end{align*}.
$$
由$\begin{pmatrix}x&-1\\1&0\end{pmatrix}:(f_{n+1},f_n)\mapsto (f_{n+2},f_{n+1})$与
$$
\begin{pmatrix}x&-1\\1&0\end{pmatrix}\sim\mathrm{diag}\left(\dfrac{x-\sqrt{x^2-4}}{2},\dfrac{x+\sqrt{x^2-4}}{2}\right):=\mathrm{diag}(a(x),b(x))
$$
可知
$$
\begin{align*}
(a-b)(x)f_n(x)=&[a(x)P_G(x)-P_{G-j}(x)]a(x)^n\\
&-[b(x)P_G(x)-P_{G-j}(x)]b(x)^n
\end{align*}
$$
其中$b(x)\to 0$. 因此$\lim_{n\to\infty} \lambda_1^{(n)}$之极限为
$$
\dfrac{x+\sqrt{x^2-4}}{2}P_G(x)=P_{G-j}(x)
$$
之最大(正实)根.
